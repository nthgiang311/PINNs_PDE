{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AKEdSlV-i_Ts"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "from torch.autograd import grad\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(torch.nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(DNN, self).__init__()\n",
        "\n",
        "        # parameters\n",
        "        self.depth = len(layers) - 1\n",
        "\n",
        "        # set up layer order dict\n",
        "        self.activation = torch.nn.Tanh\n",
        "\n",
        "        layer_list = list()\n",
        "        for i in range(self.depth - 1):\n",
        "            layer_list.append(\n",
        "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
        "            )\n",
        "            layer_list.append(('activation_%d' % i, self.activation()))\n",
        "\n",
        "        layer_list.append(\n",
        "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
        "        )\n",
        "        layerDict = OrderedDict(layer_list)\n",
        "\n",
        "        # deploy layers\n",
        "        self.layers = torch.nn.Sequential(layerDict)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out\n",
        "\n",
        "class PhysicsInformedNN():\n",
        "    def __init__(self, X, Xb, ub, layers, lr, device):\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # data trong miền\n",
        "        self.x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
        "        self.y = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
        "\n",
        "        # data trên biên\n",
        "        self.xb = torch.tensor(Xb[:, 0:1], requires_grad=True).float().to(device)\n",
        "        self.yb = torch.tensor(Xb[:, 1:2], requires_grad=True).float().to(device)\n",
        "        self.ub = torch.tensor(ub).float().to(device)\n",
        "\n",
        "\n",
        "\n",
        "        # deep neural networks\n",
        "        self.dnn = DNN(layers).to(device)\n",
        "        self.lr = lr\n",
        "\n",
        "        # optimizers: using the same settings\n",
        "        self.optimizer = torch.optim.LBFGS(\n",
        "            self.dnn.parameters(),\n",
        "            lr=1.0,\n",
        "            max_iter=20,\n",
        "            history_size=50,\n",
        "            tolerance_grad=1e-5,\n",
        "            tolerance_change=1.0 * np.finfo(float).eps,\n",
        "            line_search_fn=\"strong_wolfe\"       # can be \"strong_wolfe\"\n",
        "        )\n",
        "\n",
        "        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters())\n",
        "        self.iter = 0\n",
        "        self.losses_hist = []\n",
        "\n",
        "    def net_u(self, x, y):\n",
        "\n",
        "        outputs = self.dnn(torch.cat([x,y], dim=1))\n",
        "        u = outputs[:, 0]\n",
        "        return u\n",
        "\n",
        "    def net_f(self, x, y, xb, yb):\n",
        "        u = self.net_u(x, y)\n",
        "        u_b = self.net_u(xb, yb)\n",
        "\n",
        "        u_x, u_y = torch.autograd.grad(outputs=u, inputs=[x, y],\n",
        "                                            grad_outputs=torch.ones_like(u),\n",
        "                                            retain_graph=True, create_graph=True)\n",
        "\n",
        "        u_xx = torch.autograd.grad(outputs=u_x, inputs=x, grad_outputs=torch.ones_like(u_x),\n",
        "                                   retain_graph=True, create_graph=True)[0]\n",
        "        u_yy = torch.autograd.grad(outputs=u_y, inputs=y, grad_outputs=torch.ones_like(u_y),\n",
        "                                   retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        res =  (u_xx + u_yy) + 5 * torch.pi**2 * torch.sin(2*torch.pi * x) * torch.sin(torch.pi * y)\n",
        "        res_b = u_b - self.ub\n",
        "\n",
        "        return res, res_b\n",
        "\n",
        "\n",
        "\n",
        "    def loss_func(self):\n",
        "        start_epoch = time.time()\n",
        "        res, res_b = self.net_f(self.x, self.y, self.xb, self.yb)\n",
        "\n",
        "        mse_loss = torch.nn.MSELoss()\n",
        "        loss = mse_loss(res, torch.zeros_like(res)) + mse_loss(res_b, torch.zeros_like(res_b))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        #loss.backward()\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "\n",
        "        self.iter += 1\n",
        "        self.losses_hist.append(loss.item())\n",
        "        print(\"Epoch L-BFGS [%d], Loss: %.8f, Time: %.4fs\" % (self.iter, loss.item(), time.time()-start_epoch))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def train(self, nIter_Adam, nIter_Lbfgs):\n",
        "        self.dnn.train()\n",
        "        total_time = 0\n",
        "        for epoch in range(nIter_Adam):\n",
        "            start_epoch = time.time()\n",
        "\n",
        "            res, res_b = self.net_f(self.x, self.y, self.xb, self.yb)\n",
        "\n",
        "            mse_loss = torch.nn.MSELoss()\n",
        "            loss = mse_loss(res, torch.zeros_like(res)) + mse_loss(res_b, torch.zeros_like(res_b))\n",
        "\n",
        "            # Backward and optimize\n",
        "            self.optimizer_Adam.zero_grad()\n",
        "            #loss.backward()\n",
        "            loss.backward(retain_graph=True)  # Trong vòng lặp Adam\n",
        "\n",
        "            self.optimizer_Adam.step()\n",
        "\n",
        "            self.losses_hist.append(loss.item())\n",
        "            total_time += time.time() - start_epoch\n",
        "            print(\"Epoch Adam [%d], Loss: %.8f, Time: %.4fs\" % (epoch, loss.item(), time.time()-start_epoch))\n",
        "\n",
        "        for epoch in range(nIter_Lbfgs):\n",
        "            start_epoch = time.time()\n",
        "\n",
        "            self.optimizer.step(self.loss_func)\n",
        "\n",
        "        # Cập nhật tổng thời gian\n",
        "            total_time += time.time() - start_epoch\n",
        "        print(\"Total training time: %.4fs\" % total_time)\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        x = torch.tensor(X[:, 0:1]).float().to(self.device)\n",
        "        y = torch.tensor(X[:, 1:2]).float().to(self.device)\n",
        "\n",
        "        self.dnn.eval()\n",
        "        u = self.net_u(x, y)\n",
        "        return u\n"
      ],
      "metadata": {
        "id": "pDJ5g3o2jGG7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exact_solution(x, y):\n",
        "    u = np.sin(2 * np.pi * x) * np.sin(2 * np.pi * y)\n",
        "    return u\n",
        "\n",
        "\n",
        "def generate_data(x_samples, y_samples, xb_samples, yb_samples):\n",
        "    data = []\n",
        "    data_b = []\n",
        "\n",
        "    for x in x_samples:\n",
        "        for y in y_samples:\n",
        "            if x != 0 and x != 1 and y != 0 and y != 1:\n",
        "                u = exact_solution(x, y)\n",
        "                data.append([x, y, u])\n",
        "\n",
        "    for x in xb_samples:\n",
        "        for y in yb_samples:\n",
        "            if x == 0 or x == 1 or y == 0 or y == 1:\n",
        "                data_b.append([x, y, 0])\n",
        "\n",
        "\n",
        "    return np.array(data, dtype=np.float32), np.array(data_b, dtype=np.float32)\n",
        "\n",
        "def generate_test_data(x_samples, y_samples):\n",
        "    data = []\n",
        "\n",
        "    for x in x_samples:\n",
        "        for y in y_samples:\n",
        "            u = exact_solution(x, y)\n",
        "            data.append([x, y, u])\n",
        "    return np.array(data, dtype=np.float32)\n",
        "\n",
        "def generate_arbitrary_test_points(total_points=100, seed=42):\n",
        "    np.random.seed(seed)  # Fix the seed to ensure reproducibility\n",
        "\n",
        "    # Calculate the number of interior and boundary points based on the 3:7 ratio\n",
        "    n_boundary = int(0.3 * total_points)\n",
        "    n_interior = int(0.7 * total_points)\n",
        "\n",
        "    # Generate interior points (uniform random sampling inside the domain)\n",
        "    x_interior = np.random.uniform(0, 1, n_interior)\n",
        "    y_interior = np.random.uniform(0, 1, n_interior)\n",
        "\n",
        "    # Generate boundary points by sampling along the edges of the domain\n",
        "    x_boundary = np.concatenate([np.zeros(n_boundary//4), np.ones(n_boundary//4), np.random.uniform(0, 1, n_boundary//4), np.random.uniform(0, 1, n_boundary//4)])\n",
        "    y_boundary = np.concatenate([np.random.uniform(0, 1, n_boundary//4), np.random.uniform(0, 1, n_boundary//4), np.zeros(n_boundary//4), np.ones(n_boundary//4)])\n",
        "\n",
        "\n",
        "    # Combine interior, initial and boundary points\n",
        "    x_combined = np.concatenate([x_interior, x_boundary])\n",
        "    y_combined = np.concatenate([y_interior, y_boundary])\n",
        "\n",
        "\n",
        "    # Calculate the exact solution for each (x, y, t) pair\n",
        "    u_combined = exact_solution(x_combined, y_combined)\n",
        "\n",
        "    # Stack the (x, y, t, u) data together\n",
        "    data_test = np.vstack((x_combined, y_combined, u_combined)).T\n",
        "\n",
        "    return data_test\n",
        "\n",
        "def data_process():\n",
        "    delta_y = 0.05\n",
        "    delta_x = 0.05\n",
        "\n",
        "    delta_yb = 0.025\n",
        "    delta_xb = 0.025\n",
        "\n",
        "\n",
        "    # Define space and time discretization\n",
        "    x_samples = np.arange(0, 1.0+delta_x, delta_x)\n",
        "    y_samples = np.arange(0, 1.0+delta_y, delta_y)\n",
        "\n",
        "    xb_samples = np.arange(0, 1.0+delta_xb, delta_xb)\n",
        "    yb_samples = np.arange(0, 1.0+delta_yb, delta_yb)\n",
        "\n",
        "\n",
        "    data, data_b = generate_data(x_samples, y_samples, xb_samples, yb_samples)\n",
        "    return data, data_b"
      ],
      "metadata": {
        "id": "-PolONEajICG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    data, data_b = data_process()\n",
        "\n",
        "    layers = [2, 16, 16, 16, 16, 16, 1]\n",
        "    X_train = data[:,0:3]\n",
        "    Xb = data_b[:, 0:2]\n",
        "    ub = data_b[:,2]\n",
        "    # training\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = PhysicsInformedNN(X_train, Xb, ub, layers, lr=1e-3, device=device)\n",
        "    model.train(nIter_Adam= 1000, nIter_Lbfgs=300)\n",
        "\n",
        "    # Test data generation\n",
        "    data_test = generate_arbitrary_test_points(total_points=500, seed=42)\n",
        "\n",
        "\n",
        "    # Model predictions\n",
        "    u_pred = model.predict(data_test[:,0:2])\n",
        "\n",
        "    u_test = torch.tensor(data_test[:, 2], dtype=torch.float32, requires_grad=False).to(device)\n",
        "    # Calculate L2 error\n",
        "    mse_loss = torch.nn.MSELoss()\n",
        "    L2 = mse_loss(u_pred, u_test)\n",
        "\n",
        "    print(\"L2 =\", L2)\n",
        "\n",
        "    # Plot loss history\n",
        "    plot_loss(model.losses_hist, ylabel='Loss')\n",
        "    return model\n",
        "\n",
        "\n",
        "'''def plot_loss(losses, ylabel):\n",
        "    epochs = len(losses)\n",
        "    x_epochs = np.arange(1, epochs + 1)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(x_epochs, losses, color='blue')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n",
        "    plt.savefig('loss_his.png')\n",
        "    plt.show()'''\n",
        "def plot_loss(losses, ylabel):\n",
        "    epochs = len(losses)\n",
        "    x_epochs = np.arange(1, epochs + 1)\n",
        "\n",
        "    # Save loss history to txt file\n",
        "    np.savetxt('loss_history.txt', np.column_stack((x_epochs, losses)),\n",
        "               header='Epoch\\tLoss', fmt=['%d', '%.10e'], delimiter='\\t')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(x_epochs, losses, color='blue')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(ylabel)\n",
        "\n",
        "    plt.yscale('log')  # Use log scale\n",
        "\n",
        "    ax = plt.gca()\n",
        "\n",
        "    # Set ticks only at powers of 10\n",
        "    loc = mtick.LogLocator(base=10.0, subs=(1.0,), numticks=12)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "\n",
        "    # Format ticks as 10^x\n",
        "    formatter = mtick.FuncFormatter(lambda y, _: r'$10^{{{}}}$'.format(int(np.log10(y))))\n",
        "    ax.yaxis.set_major_formatter(formatter)\n",
        "\n",
        "    plt.grid(True, which=\"both\", ls=\"--\", lw=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('loss_his.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = train()\n"
      ],
      "metadata": {
        "id": "A0mAx3CejKqw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}